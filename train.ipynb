{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "TRAIN_DIR = 'train_augmented'\n",
    "TEST_DIR = 'test'\n",
    "RES_DIR = 'results'\n",
    "\n",
    "train_features_path = os.path.join(RES_DIR, 'train_features')\n",
    "test_features_path = os.path.join(RES_DIR, 'test_features')\n",
    "test_labels_path = os.path.join(RES_DIR, 'test_labels')\n",
    "scaler_path = os.path.join(RES_DIR, 'scaler')\n",
    "scaled_train_path = os.path.join(RES_DIR, 'scaled_train')\n",
    "scaled_test_path = os.path.join(RES_DIR, 'scaled_test')\n",
    "pca_path = os.path.join(RES_DIR, 'pca')\n",
    "best_params_svm_path = os.path.join(RES_DIR, 'best_params_svm')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filepath     label\n",
      "0    images/test/negative/342.jpg  negative\n",
      "1    images/test/negative/159.jpg  negative\n",
      "2    images/test/negative/198.jpg  negative\n",
      "3    images/test/negative/275.jpg  negative\n",
      "4    images/test/negative/484.jpg  negative\n",
      "..                            ...       ...\n",
      "371        images/test/mink/5.jpg      mink\n",
      "372       images/test/mink/42.jpg      mink\n",
      "373        images/test/mink/0.jpg      mink\n",
      "374       images/test/mink/44.jpg      mink\n",
      "375       images/test/mink/43.jpg      mink\n",
      "\n",
      "[376 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# construct pandas dataframes\n",
    "def construct_dataframe(dir):\n",
    "    label_dirs = os.listdir(dir)\n",
    "    dataframe_data = []\n",
    "    \n",
    "    for label in label_dirs:\n",
    "        label_path = os.path.join(dir, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for image_name in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image_name)\n",
    "                dataframe_data.append([image_path, label])\n",
    "    \n",
    "    df = pd.DataFrame(dataframe_data, columns=['filepath', 'label'])\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = construct_dataframe(TRAIN_DIR)\n",
    "test_df = construct_dataframe(TEST_DIR)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2505 validated image filenames belonging to 1 classes.\n",
      "Found 376 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image_gen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
    "# )\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
    ")\n",
    "\n",
    "train_flow = image_gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    interpolation=\"bilinear\",\n",
    ")\n",
    "\n",
    "test_flow = image_gen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resnet(X):\n",
    "    resnet_model = ResNet50(weights='imagenet', include_top=False, classes=False)\n",
    "\n",
    "    features_array = resnet_model.predict(X)\n",
    "    features_array = np.reshape(features_array, (-1, features_array.shape[1]*features_array.shape[2]*\n",
    "                                                 features_array.shape[3]))\n",
    "        \n",
    "    return features_array\n",
    "\n",
    "\n",
    "train_features = extract_resnet(train_flow)\n",
    "with open(train_features_path, 'wb') as f:\n",
    "    pickle.dump(train_features, f)\n",
    "\n",
    "test_features = extract_resnet(test_flow)\n",
    "with open(test_features_path, 'wb') as f:\n",
    "    pickle.dump(test_features, f)\n",
    "\n",
    "with open(test_labels_path, 'wb') as f:\n",
    "    pickle.dump(np.where(test_df['label'].to_numpy()=='positive', 1, -1), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load resnet features\n",
    "with open(train_features_path, 'rb') as f:\n",
    "    train_features = pickle.load(f)\n",
    "\n",
    "with open(test_features_path, 'rb') as f:\n",
    "    test_features = pickle.load(f)\n",
    "with open(test_labels_path, 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance percentage = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Apply standard scaler to output from resnet50\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_features)\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(ss, f)\n",
    "\n",
    "train_features = ss.transform(train_features)\n",
    "test_features = ss.transform(test_features)\n",
    "\n",
    "with open(scaled_train_path, 'wb') as f:\n",
    "    pickle.dump(train_features, f)\n",
    "\n",
    "with open(scaled_test_path, 'wb') as f:\n",
    "    pickle.dump(test_features, f)\n",
    "\n",
    "    \n",
    "# Take PCA to reduce feature space dimensionality\n",
    "pca = PCA(n_components=512, whiten=True)\n",
    "pca = pca.fit(train_features)\n",
    "\n",
    "with open(pca_path 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "\n",
    "train_features = pca.transform(train_features)\n",
    "test_features = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23474178403755872\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.23058823529411762\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.2311320754716981\n",
      "0.16770186335403728\n",
      "0.152317880794702\n",
      "0.15576323987538943\n",
      "0.16000000000000003\n",
      "0.2098360655737705\n",
      "0.2027027027027027\n",
      "0.16835016835016836\n",
      "0.18118466898954705\n",
      "0.19444444444444445\n",
      "0.1741935483870968\n",
      "0.19548872180451127\n",
      "0.21960784313725493\n",
      "0.21926910299003322\n",
      "0.22471910112359553\n",
      "0.17177914110429449\n",
      "0.16314199395770393\n",
      "0.1796875\n",
      "0.18374558303886926\n",
      "0.1346153846153846\n",
      "0.134185303514377\n",
      "0.16494845360824742\n",
      "0.16783216783216787\n",
      "0.16091954022988508\n",
      "0.18532818532818532\n",
      "0.15709969788519634\n",
      "0.15432098765432098\n",
      "{'gamma': 0.001, 'kernel': 'rbf', 'nu': 0.05, 'shrinking': True}\n",
      "Best score: 0.23474178403755872\n"
     ]
    }
   ],
   "source": [
    "# Train classifier and obtain predictions for OC-SVM\n",
    "grid = {\n",
    "    'gamma': [0.001, 0.0001, 0.00001, 0.000001, 'auto', 'scale'],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'nu': [0.01, 0.02, 0.05, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24, 0.26],\n",
    "    'shrinking': [True, False]\n",
    "}\n",
    "# grid = {\n",
    "#     'gamma': [0.001],\n",
    "#     'kernel': ['rbf'],\n",
    "#     'nu': [0.08],\n",
    "#     'shrinking': [False]\n",
    "# }\n",
    "\n",
    "\n",
    "oc_svm = svm.OneClassSVM()\n",
    "best_score = -1\n",
    "\n",
    "for params in ParameterGrid(grid):\n",
    "    oc_svm.set_params(**params)\n",
    "    oc_svm.fit(train_features)\n",
    "    \n",
    "    y_pred = oc_svm.predict(test_features)\n",
    "    score = f1_score(test_labels, y_pred)\n",
    "    print(score)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "        best_y_pred = y_pred\n",
    "\n",
    "    \n",
    "print(best_params)\n",
    "print('Best score:', best_score)\n",
    "print()\n",
    "\n",
    "with open(best_params_svm_path, 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     'gamma': [0.001, 0.0001, 0.00001, 0.000001, 'auto', 'scale'],\n",
    "#     'kernel': ['rbf', 'linear'],\n",
    "#     'nu': [0.01, 0.02, 0.05, 0.08, 0.10, 0.12],\n",
    "#     'shrinking': [True, False]\n",
    "# }\n",
    "grid = {\n",
    "    'contamination': [0.01, 0.08],\n",
    "    'max_features': [1, 2, 3, 4, 5],\n",
    "    'max_samples': [1, 2, 3, 4, 5],\n",
    "    'n_estimators': [40, 100, 120, 150, 300]\n",
    "}\n",
    "\n",
    "\n",
    "if_clf = IsolationForest()\n",
    "best_score = -1\n",
    "\n",
    "for params in ParameterGrid(grid):\n",
    "    if_clf.set_params(**params)\n",
    "    if_clf.fit(train_features)\n",
    "    \n",
    "    y_pred = if_clf.predict(test_features)\n",
    "    score = f1_score(test_labels, y_pred)\n",
    "    print(score)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "        best_y_pred = y_pred\n",
    "\n",
    "    \n",
    "print(best_params)\n",
    "print('Best score:', best_score)\n",
    "\n",
    "with open(best_params_if_path, 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1 -1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1  1  1 -1\n",
      "  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1 -1 -1  1 -1 -1  1  1  1  1 -1  1\n",
      " -1  1 -1 -1 -1 -1  1 -1  1  1 -1  1  1 -1  1 -1  1  1 -1 -1  1 -1  1  1\n",
      " -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1 -1  1 -1 -1  1  1 -1\n",
      " -1  1  1 -1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1 -1 -1\n",
      " -1  1  1 -1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1\n",
      " -1 -1 -1  1  1 -1  1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1 -1  1  1  1 -1\n",
      " -1  1  1  1 -1  1  1  1 -1 -1  1  1  1 -1 -1 -1  1  1  1 -1  1  1  1  1\n",
      "  1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1 -1  1  1 -1 -1\n",
      " -1 -1 -1 -1 -1  1  1  1 -1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1 -1 -1 -1\n",
      "  1  1 -1  1  1  1 -1  1 -1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1 -1  1  1\n",
      " -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1  1  1  1\n",
      "  1 -1  1  1  1  1 -1 -1  1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1  1 -1 -1\n",
      " -1 -1  1  1  1 -1  1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1 -1  1  1 -1\n",
      " -1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1\n",
      " -1  1  1 -1 -1  1 -1  1 -1 -1  1  1  1 -1 -1 -1  1 -1  1 -1  1 -1 -1 -1\n",
      "  1  1  1 -1 -1 -1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1\n",
      "  1 -1  1 -1  1  1 -1  1 -1  1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1 -1 -1\n",
      "  1  1 -1 -1  1 -1  1  1 -1  1  1  1  1  1 -1 -1 -1  1 -1  1  1 -1  1 -1\n",
      " -1  1 -1 -1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1  1 -1\n",
      "  1  1 -1  1  1 -1  1 -1  1  1  1  1 -1 -1  1  1  1 -1  1  1  1 -1 -1 -1\n",
      " -1  1 -1 -1 -1  1  1  1  1  1  1  1 -1 -1  1  1  1 -1 -1  1  1 -1  1  1\n",
      "  1  1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1  1  1  1 -1  1 -1 -1 -1  1  1\n",
      " -1 -1  1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1 -1 -1 -1  1  1  1\n",
      "  1 -1  1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1  1  1  1  1\n",
      " -1 -1 -1 -1  1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1 -1  1  1\n",
      "  1 -1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1 -1  1\n",
      " -1 -1  1  1  1 -1 -1] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(best_y_pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
